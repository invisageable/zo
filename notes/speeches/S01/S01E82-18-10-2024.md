# S01E82 — 18-10-2024.

> *Du code chirurgical.*

[prev](S01E81-17-10-2024.md) — [next](S01E83-19-10-2024.md)   

## jour 82.

La précision nécessaire pour transformer un langage de balisage en une collection de jetons est ultra minutieuse. Cela se joue au caractère près, il ne faut pas se louper dans l'implémentation du tokenizer. Certains utiliserons un système d'expressions régulières pour reconnaître un ensemble de pattern. Après moulte écriture du Tokenizer, je me convains que la machine à état est l'implémentation chirurgicale adapter pour cela. Il n'y a pas mieux pour avoir un contrôle fin.   

A chaque état, on peut analyser, un jeu de caractère our orienter le curseur vers la prochain état correspondant. Certes, c'est une implémentation longue mais parfois, on ne peut pas tricher pour simuler l'analyse lexicale. J'ai été longuement bloqué dans la récupération des attributs d'une balise. Mon tableau qui collecte l'ensemble des attributs était constamment vide. En reprenant mes travaux, je me suis rendu compte de mon erreur. Ma méthode `finish_attribute` n'ajouter pas l'attribut depuis la référence de la balise courante. J'ajoutais l'attribut courant dans un tableau que je n'utilisais pas du tout. Une zboonerie pas évitante à détecter.   

Suite à ça, j'ai réorganiser une grande partie du Tokenizer pour distinguer clairement chaque mode du Tokenizer. En guise de rappelle, mon langage doit être capable d'analyser trois langages:

- Un langage de programmation.
- Un langage de balisage.
- Un langage de mise en forme de document.

Je ne sais pas du tout comment les autres font, mais pour ma part, j'ai un tokenizer multi-fonctions comme un couteau suisse qui est capable de s'adapter à chaque symbole. C-à-d que les symboles entre eux n'auront aucun conflit. Par exemple, le symbole `<` a une signification différente dans les trois langages. J'ai rajouter une couche de logique pour permettre au tokenizer d'identifier parfaitement les trois syntaxes. Je suis très satisfait du comportement obtenu. Pour un début, c'est prometteur. Et tout cela n'aurait pu être possible sans la machine à état. C'est vraiment une dinguerie comme implémentation, une fois le concept compris, c'est un plaisir à mettre en place. Je conseille à 100% pour tout ce qui touche à l'analyse lexicale ou syntaxique.   

Il me semble, donc tu me corrigeras si je m'égare mais dans l'industrie du jeu viédo, ils sont assez friands des machines à états. Ce qui semble logique pour les actions d'un personnage (marcher, courrir, trotiner, ramper, etc). De cette façon, tu peux couplet mouvements, sons, etc en fonction de l'état en cours. C'est ultra adapté en tout cas. Ça serait tellement le turfu qu'un développeur de jeux vidéos, nous confirme déjà si c'est vrai et nous raconte dans quel contexte ils utilisent une machine à état finis.   

En attendant, je suis tout de mêne curieux de connaître comment toi tu implémentes ton tokenizer. Tu as surement développé un jutsu secret que je ne connais pas encore. Alors n'hésite pas à m'en faire part.    

[@invisageable](https://twitter.com/invisageable)   

---

[prev](S01E81-17-10-2024.md) — [next](S01E83-19-10-2024.md)   
